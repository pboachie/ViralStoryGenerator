services:
  redis:
    image: redis:7-alpine
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    restart: always
    networks:
      - viral-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 5s
    command: redis-server --appendonly yes
    deploy:
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.1'
          memory: 128M

  redis-exporter:
    image: oliver006/redis_exporter:latest
    environment:
      - REDIS_ADDR=redis://redis:6379
    ports:
      - "9121:9121"
    networks:
      - viral-network
    restart: always
    depends_on:
      - redis
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          cpus: '0.2'
          memory: 128M

  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      redis:
        condition: service_healthy
    environment:
      # General
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - APP_VERSION=${APP_VERSION}
      - APP_TITLE=${APP_TITLE}
      - APP_DESCRIPTION=${APP_DESCRIPTION}
      - BASE_URL=${BASE_URL}

      # Redis
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_ENABLED=${REDIS_ENABLED:-True}
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_QUEUE_NAME=${REDIS_QUEUE_NAME:-api_jobs}
      - REDIS_RESULT_PREFIX=${REDIS_RESULT_PREFIX:-api_jobs_result:}
      - REDIS_SCRAPE_QUEUE_NAME=${REDIS_SCRAPE_QUEUE_NAME:-scraper_jobs}
      - REDIS_SCRAPE_RESULT_PREFIX=${REDIS_SCRAPE_RESULT_PREFIX:-scraper_jobs_result:}
      - REDIS_RESULT_TTL=${REDIS_RESULT_TTL:-3600}

      # LLM Configuration
      - LLM_ENDPOINT=${LLM_ENDPOINT}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_MODEL_MULTI=${LLM_MODEL_MULTI}
      - LLM_MODEL_SMALL=${LLM_MODEL_SMALL}
      - LLM_MODEL_LARGE=${LLM_MODEL_LARGE}
      - LLM_CHUNK_SIZE=${LLM_CHUNK_SIZE:-5000}
      - LLM_SHOW_THINKING=${LLM_SHOW_THINKING:-False}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-32768}
      - LLM_CLEANING_MAX_PROMPT_CHARS=${LLM_CLEANING_MAX_PROMPT_CHARS:-500000}
      - LLM_CLEANING_MAX_OUTPUT_TOKENS=${LLM_CLEANING_MAX_OUTPUT_TOKENS:-32768}
      - LLM_MIN_CLEANING_LENGTH=${LLM_MIN_CLEANING_LENGTH:-200}

      # ElevenLabs API Configuration
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - ELEVENLABS_VOICE_ID=${ELEVENLABS_VOICE_ID}
      - ENABLE_AUDIO_GENERATION=${ENABLE_AUDIO_GENERATION:-False}
      - ELEVENLABS_MODEL_ID=${ELEVENLABS_MODEL_ID:-eleven_multilingual_v2}
      - ELEVENLABS_STABILITY=${ELEVENLABS_STABILITY:-0.5}
      - ELEVENLABS_SIMILARITY_BOOST=${ELEVENLABS_SIMILARITY_BOOST:-0.75}

      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ENABLE_IMAGE_GENERATION=${ENABLE_IMAGE_GENERATION:-False}

      # Storage
      - STORAGE_PROVIDER=${STORAGE_PROVIDER:-local}
      - LOCAL_STORAGE_PATH=${LOCAL_STORAGE_PATH:-/app/storage}
      - AUDIO_STORAGE_PATH=${AUDIO_STORAGE_PATH:-/app/storage/audio}
      - STORY_STORAGE_PATH=${STORY_STORAGE_PATH:-/app/storage/stories}
      - STORYBOARD_STORAGE_PATH=${STORYBOARD_STORAGE_PATH:-/app/storage/storyboards}
      - SCREENSHOT_STORAGE_PATH=${SCREENSHOT_STORAGE_PATH:-/app/storage/screenshots}
      - FILE_RETENTION_DAYS=${FILE_RETENTION_DAYS:-30}
      - CLEANUP_INTERVAL_HOURS=${CLEANUP_INTERVAL_HOURS:-24}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_REGION=${S3_REGION}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME}

      # HTTP API Options & Security
      - HTTP_TIMEOUT=${HTTP_TIMEOUT:-120}
      - API_KEY_ENABLED=${API_KEY_ENABLED:-False}
      - API_KEY=${API_KEY}
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-True}
      - RATE_LIMIT_REQUESTS=${RATE_LIMIT_REQUESTS:-100}
      - RATE_LIMIT_WINDOW=${RATE_LIMIT_WINDOW:-60}
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
      - MAX_UPLOAD_SIZE_MB=${MAX_UPLOAD_SIZE_MB:-50}
      - MAX_REQUEST_SIZE_MB=${MAX_REQUEST_SIZE_MB:-10}
      - VOICE_ID_PATTERN=${VOICE_ID_PATTERN}
      - SANITIZE_MAX_LENGTH=${SANITIZE_MAX_LENGTH:-1000}
      - DANGEROUS_CHARS=${DANGEROUS_CHARS}
      - ALLOWED_FILE_TYPES=${ALLOWED_FILE_TYPES}
      - SOURCE_MATERIALS_PATH=${SOURCE_MATERIALS_PATH:-/app/data/sources}

      # RAG Configuration
      - RAG_ENABLED=${RAG_ENABLED:-True}
      - RAG_EMBEDDING_MODEL=${RAG_EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      - RAG_VECTOR_DB_PATH=${RAG_VECTOR_DB_PATH:-/app/vector_db}
      - RAG_RELEVANT_CHUNKS_COUNT=${RAG_RELEVANT_CHUNKS_COUNT:-5}
      - RAG_CHUNK_SIZE=${RAG_CHUNK_SIZE:-500}
      - RAG_CHUNK_OVERLAP=${RAG_CHUNK_OVERLAP:-50}

      # Storyboard Settings
      - STORYBOARD_WPM=${STORYBOARD_WPM:-150}
      - ENABLE_STORYBOARD_GENERATION=${ENABLE_STORYBOARD_GENERATION:-True}

      # Monitoring (App's own health endpoint)
      - HEALTH_CHECK_ENABLED=${HEALTH_CHECK_ENABLED:-True}
      - HEALTH_CHECK_ENDPOINT=${HEALTH_CHECK_ENDPOINT:-/health}
      - METRICS_ENABLED=${METRICS_ENABLED:-True}
      - METRICS_ENDPOINT=${METRICS_ENDPOINT:-/metrics}

    networks:
      - viral-network
    restart: always
    deploy:
      mode: replicated
      replicas: ${BACKEND_REPLICAS:-2}
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    volumes:
      - ./storage:/app/storage
      - ./vector_db:/app/vector_db
      - ./data/sources:/app/data/sources
      - ${ENV_FILE:-./.env}:/app/.env:ro
    command: python3 -m viralStoryGenerator.src.worker_runner api --port 8000 --reload --reload-exclude="*.log"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${API_PORT:-8000}${HEALTH_CHECK_ENDPOINT:-/health}"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s

  scraper:
    build:
      context: .
      dockerfile: Dockerfile.worker
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    environment:
      # General
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENVIRONMENT=${ENVIRONMENT:-production}

      # Redis
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_ENABLED=${REDIS_ENABLED:-True}
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_WORKER_BATCH_SIZE=${WORKER_BATCH_SIZE:-1} # Using generic WORKER_BATCH_SIZE from .env
      - REDIS_WORKER_MAX_CONCURRENT=${WORKER_CONCURRENT:-1} # Using generic WORKER_CONCURRENT from .env
      - REDIS_WORKER_SLEEP_INTERVAL=${REDIS_WORKER_SLEEP_INTERVAL:-1}
      - REDIS_SCRAPE_QUEUE_NAME=${REDIS_SCRAPE_QUEUE_NAME:-scraper_jobs} # Scraper specific queue
      - REDIS_SCRAPE_RESULT_PREFIX=${REDIS_SCRAPE_RESULT_PREFIX:-scraper_jobs_result:} # Scraper specific result prefix
      - REDIS_SCRAPE_RESULT_TTL=${REDIS_SCRAPE_RESULT_TTL:-3600}

      # Scraper Configuration (Crawl4AI specific)
      - SCRAPER_BM25_THRESHOLD=${SCRAPER_BM25_THRESHOLD:-1.2}
      - SCRAPER_PRUNING_THRESHOLD=${SCRAPER_PRUNING_THRESHOLD:-0.48}
      - SCRAPER_PRUNING_THRESHOLD_TYPE=${SCRAPER_PRUNING_THRESHOLD_TYPE:-fixed}
      - SCRAPER_MD_IGNORE_LINKS=${SCRAPER_MD_IGNORE_LINKS:-True}
      - SCRAPER_CHECK_ROBOTS_TXT=${SCRAPER_CHECK_ROBOTS_TXT:-True}

      # Scraper Rate Limiter Configuration
      - SCRAPER_RL_BASE_DELAY=${SCRAPER_RL_BASE_DELAY:-"1.0,3.0"}
      - SCRAPER_RL_MAX_DELAY=${SCRAPER_RL_MAX_DELAY:-60.0}
      - SCRAPER_RL_MAX_RETRIES=${SCRAPER_RL_MAX_RETRIES:-3}
      - SCRAPER_RL_CODES=${SCRAPER_RL_CODES:-"429,503"}

      # Scraper Crawler Monitor Configuration
      - SCRAPER_MONITOR_ENABLED=${SCRAPER_MONITOR_ENABLED:-False}
      - SCRAPER_MONITOR_MAX_ROWS=${SCRAPER_MONITOR_MAX_ROWS:-10}
      - SCRAPER_MONITOR_DISPLAY_MODE=${SCRAPER_MONITOR_DISPLAY_MODE:-AGGREGATED}

      # Scraper Dispatcher Configuration
      - SCRAPER_DISP_SEMA_MAX_PERMIT=${SCRAPER_DISP_SEMA_MAX_PERMIT:-10}
      - SCRAPER_DISP_MEM_THRESHOLD=${SCRAPER_DISP_MEM_THRESHOLD:-85.0}
      - SCRAPER_DISP_MEM_INTERVAL=${SCRAPER_DISP_MEM_INTERVAL:-1.0}
      - SCRAPER_DISP_MEM_MAX_PERMIT=${SCRAPER_DISP_MEM_MAX_PERMIT:-5}
      - SCRAPER_DISP_MEM_WAIT_TIMEOUT=${SCRAPER_DISP_MEM_WAIT_TIMEOUT:-300.0}

      # Scraper Worker Specific Configuration
      - SCRAPER_WORKER_MAX_CONCURRENT_JOBS=${SCRAPER_WORKER_MAX_CONCURRENT_JOBS:-2}
      - SCRAPER_WORKER_SHUTDOWN_TIMEOUT=${SCRAPER_WORKER_SHUTDOWN_TIMEOUT:-30}
      - SCRAPER_ARUN_MANY_TIMEOUT=${SCRAPER_ARUN_MANY_TIMEOUT:-60.0}

      # Storage for screenshots
      - STORAGE_PROVIDER=${STORAGE_PROVIDER:-local} # If scraper writes directly
      - LOCAL_STORAGE_PATH=${LOCAL_STORAGE_PATH:-/app/storage}
      - SCREENSHOT_STORAGE_PATH=${SCREENSHOT_STORAGE_PATH:-/app/storage/screenshots}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_REGION=${S3_REGION}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME}

    networks:
      - viral-network
    restart: always
    deploy:
      mode: replicated
      replicas: ${SCRAPER_REPLICAS:-3}
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        max_attempts: 5
        window: 120s
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    volumes:
      - ./data:/app/data
      - ./storage:/app/storage
      - ${ENV_FILE:-./.env}:/app/.env:ro
    command: python3 -m viralStoryGenerator.src.worker_runner worker --worker-type scrape

  api-worker:
    build:
      context: .
      dockerfile: Dockerfile.workerapi
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    environment:
      # General
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENVIRONMENT=${ENVIRONMENT:-production}

      # Redis
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_ENABLED=${REDIS_ENABLED:-True}
      - REDIS_DB=${REDIS_DB:-0}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_WORKER_BATCH_SIZE=${WORKER_BATCH_SIZE:-1}
      - REDIS_WORKER_MAX_CONCURRENT=${WORKER_CONCURRENT:-1}
      - REDIS_WORKER_SLEEP_INTERVAL=${REDIS_WORKER_SLEEP_INTERVAL:-1}
      - REDIS_QUEUE_NAME=${REDIS_QUEUE_NAME:-api_jobs}
      - REDIS_RESULT_PREFIX=${REDIS_RESULT_PREFIX:-api_jobs_result:}
      - REDIS_RESULT_TTL=${REDIS_RESULT_TTL:-3600}

      # LLM Configuration
      - LLM_ENDPOINT=${LLM_ENDPOINT}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_MODEL_MULTI=${LLM_MODEL_MULTI}
      - LLM_MODEL_SMALL=${LLM_MODEL_SMALL}
      - LLM_MODEL_LARGE=${LLM_MODEL_LARGE}
      - LLM_CHUNK_SIZE=${LLM_CHUNK_SIZE:-5000}
      - LLM_SHOW_THINKING=${LLM_SHOW_THINKING:-False}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-32768}
      - LLM_CLEANING_MAX_PROMPT_CHARS=${LLM_CLEANING_MAX_PROMPT_CHARS:-500000}
      - LLM_CLEANING_MAX_OUTPUT_TOKENS=${LLM_CLEANING_MAX_OUTPUT_TOKENS:-32768}
      - LLM_MIN_CLEANING_LENGTH=${LLM_MIN_CLEANING_LENGTH:-200}

      # ElevenLabs API Configuration
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - ELEVENLABS_VOICE_ID=${ELEVENLABS_VOICE_ID}
      - ENABLE_AUDIO_GENERATION=${ENABLE_AUDIO_GENERATION:-False}
      - ELEVENLABS_MODEL_ID=${ELEVENLABS_MODEL_ID:-eleven_multilingual_v2}
      - ELEVENLABS_STABILITY=${ELEVENLABS_STABILITY:-0.5}
      - ELEVENLABS_SIMILARITY_BOOST=${ELEVENLABS_SIMILARITY_BOOST:-0.75}

      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ENABLE_IMAGE_GENERATION=${ENABLE_IMAGE_GENERATION:-False}

      # Storage
      - STORAGE_PROVIDER=${STORAGE_PROVIDER:-local}
      - LOCAL_STORAGE_PATH=${LOCAL_STORAGE_PATH:-/app/storage}
      - AUDIO_STORAGE_PATH=${AUDIO_STORAGE_PATH:-/app/storage/audio}
      - STORY_STORAGE_PATH=${STORY_STORAGE_PATH:-/app/storage/stories}
      - STORYBOARD_STORAGE_PATH=${STORYBOARD_STORAGE_PATH:-/app/storage/storyboards}
      - FILE_RETENTION_DAYS=${FILE_RETENTION_DAYS:-30}
      - CLEANUP_INTERVAL_HOURS=${CLEANUP_INTERVAL_HOURS:-24}
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_REGION=${S3_REGION}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
      - S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
      - AZURE_ACCOUNT_NAME=${AZURE_ACCOUNT_NAME}
      - AZURE_ACCOUNT_KEY=${AZURE_ACCOUNT_KEY}
      - AZURE_CONTAINER_NAME=${AZURE_CONTAINER_NAME}
      - SOURCE_MATERIALS_PATH=${SOURCE_MATERIALS_PATH:-/app/data/sources}

      # RAG Configuration
      - RAG_ENABLED=${RAG_ENABLED:-True}
      - RAG_EMBEDDING_MODEL=${RAG_EMBEDDING_MODEL:-all-MiniLM-L6-v2}
      - RAG_VECTOR_DB_PATH=${RAG_VECTOR_DB_PATH:-/app/vector_db}
      - RAG_RELEVANT_CHUNKS_COUNT=${RAG_RELEVANT_CHUNKS_COUNT:-5}
      - RAG_CHUNK_SIZE=${RAG_CHUNK_SIZE:-500}
      - RAG_CHUNK_OVERLAP=${RAG_CHUNK_OVERLAP:-50}

      # Storyboard Settings
      - STORYBOARD_WPM=${STORYBOARD_WPM:-150}
      - ENABLE_STORYBOARD_GENERATION=${ENABLE_STORYBOARD_GENERATION:-True}

    networks:
      - viral-network
    restart: always
    deploy:
      mode: replicated
      replicas: ${API_WORKER_REPLICAS:-1}
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        max_attempts: 5
        window: 120s
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M
    volumes:
      - ./data:/app/data
      - ./storage:/app/storage
      - ./vector_db:/app/vector_db
      - ./data/sources:/app/data/sources
      - ${ENV_FILE:-./.env}:/app/.env:ro
    command: python3 -m viralStoryGenerator.src.worker_runner worker --worker-type queue

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus/:/etc/prometheus/
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    networks:
      - viral-network
    depends_on:
      - redis
    deploy:
      placement:
        constraints:
          - node.role == manager
    restart: always

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/:/etc/grafana/provisioning/
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    networks:
      - viral-network
    depends_on:
      - prometheus
    deploy:
      placement:
        constraints:
          - node.role == manager
    restart: always

networks:
  viral-network:
    driver: overlay
    attachable: true

volumes:
  redis-data:
  prometheus-data:
  grafana-data: