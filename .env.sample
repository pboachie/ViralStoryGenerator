# ViralStoryGenerator Environment Configuration

# Application Metadata
APP_VERSION="0.1.2"
APP_TITLE="Viral Story Generator API"
APP_DESCRIPTION="API for generating viral stories from web content"

# General settings
LOG_LEVEL="DEBUG"
ENVIRONMENT="development"
SOURCES_FOLDER="./data/sources"
AUDIO_QUEUE_DIR="./data/audio"

# LLM Configuration
LLM_ENDPOINT="http://localhost:1234/v1/chat/completions"
LLM_MODEL=gemma-3-1b-it  # Default model if specific type not needed
LLM_MODEL_MULTI="model-for-structured-output" # Model optimized for JSON/tool/image output
LLM_MODEL_SMALL="small-fast-model" # Quick model for simple tasks
LLM_MODEL_LARGE="large-reasoning-model" # Powerful model for complex tasks
LLM_CHUNK_SIZE="5000" # Chunk size for LLM processing
LLM_SHOW_THINKING="False" # Show thinking process in response
LLM_TEMPERATURE="0.95" # Creativity level of the model
LLM_MAX_TOKENS="32768" # Maximum tokens for LLM response
LLM_CLEANING_MAX_PROMPT_CHARS="20000" # Maximum characters for LLM cleaning prompt
LLM_CLEANING_MAX_OUTPUT_TOKENS="4096" # Maximum tokens for LLM cleaning
LLM_MIN_CLEANING_LENGTH="200" # Minimum character length of markdown content to trigger LLM-based cleaning

# ElevenLabs API Configuration
ELEVENLABS_API_KEY="your_api_key"
ELEVENLABS_VOICE_ID="your_voice_id"
ENABLE_AUDIO_GENERATION="False"
ELEVENLABS_MODEL_ID="eleven_multilingual_v2"
ELEVENLABS_STABILITY="0.5"
ELEVENLABS_SIMILARITY_BOOST="0.75"

# OpenAI Configuration (Optional)
OPENAI_API_KEY="your_openai_key"
ENABLE_IMAGE_GENERATION="False"

# HTTP API Options
HTTP_TIMEOUT="120"
API_HOST="0.0.0.0"
API_PORT="8000"
API_WORKERS="1"

# HTTP Security Settings
API_KEY_ENABLED="False"
API_KEY="your_secure_api_key_here"

# Rate Limiting
RATE_LIMIT_ENABLED="True"
RATE_LIMIT_REQUESTS="100"
RATE_LIMIT_WINDOW="60"

# CORS Settings
CORS_ORIGINS=""

# SSL/TLS Settings (for production)
SSL_ENABLED="False"
SSL_CERT_FILE="./certs/cert.pem"
SSL_KEY_FILE="./certs/key.pem"
MAX_UPLOAD_SIZE_MB="50"
MAX_REQUEST_SIZE_MB="10"

# Redis Configuration
REDIS_ENABLED="True"
# REDIS_HOST="redis"
REDIS_HOST="localhost"
REDIS_PORT="6379"
REDIS_DB="0"
REDIS_PASSWORD=""
REDIS_QUEUE_NAME="api_jobs"
REDIS_RESULT_PREFIX="viralstory_result:"
REDIS_RESULT_TTL="3600"

# Worker Configuration
REDIS_WORKER_BATCH_SIZE="1"
REDIS_WORKER_SLEEP_INTERVAL="1"
REDIS_WORKER_MAX_CONCURRENT="1"
REDIS_SCRAPE_QUEUE_NAME="scraper_jobs"
REDIS_API_WORKER_GROUP_NAME="api_worker_group"
REDIS_SCRAPE_RESULT_PREFIX="api_jobs_result:"
REDIS_SCRAPE_RESULT_TTL="3600"

# Scraper Configuration (Crawl4AI specific)
SCRAPER_BM25_THRESHOLD="1.2" # BM25 content filter relevance threshold
SCRAPER_PRUNING_THRESHOLD="0.48" # Pruning content filter threshold
SCRAPER_PRUNING_THRESHOLD_TYPE="fixed" # Pruning threshold type: "fixed" or "percentile"
SCRAPER_MD_IGNORE_LINKS="True" # Whether to ignore links during Markdown generation
SCRAPER_CHECK_ROBOTS_TXT="True" # Whether Crawl4AI should respect robots.txt

# Scraper Rate Limiter Configuration
SCRAPER_RL_BASE_DELAY="1.0,3.0" # Comma-separated min,max delay in seconds between requests
SCRAPER_RL_MAX_DELAY="60.0" # Maximum backoff delay in seconds
SCRAPER_RL_MAX_RETRIES="3" # Maximum retries for rate-limited requests
SCRAPER_RL_CODES="429,503" # Comma-separated HTTP status codes that trigger rate limiting

# Scraper Crawler Monitor Configuration
SCRAPER_MONITOR_ENABLED="False" # Enable real-time monitoring dashboard for crawls
SCRAPER_MONITOR_MAX_ROWS="10" # Max rows in live display for monitor
SCRAPER_MONITOR_DISPLAY_MODE="AGGREGATED" # Monitor display mode: "DETAILED" or "AGGREGATED"

# Scraper Dispatcher Configuration
# Semaphore Dispatcher
SCRAPER_DISP_SEMA_MAX_PERMIT="10" # Max concurrent tasks for SemaphoreDispatcher

# MemoryAdaptive Dispatcher
SCRAPER_DISP_MEM_THRESHOLD="85.0" # Pause if memory exceeds this percentage
SCRAPER_DISP_MEM_INTERVAL="1.0" # How often (seconds) to check memory for MemoryAdaptiveDispatcher
SCRAPER_DISP_MEM_MAX_PERMIT="5" # Max concurrent tasks for MemoryAdaptiveDispatcher
SCRAPER_DISP_MEM_WAIT_TIMEOUT="300.0" # Timeout (seconds) if memory stays above threshold

# Scraper Worker Specific Configuration
SCRAPER_WORKER_MAX_CONCURRENT_JOBS="2" # Max concurrent scrape *jobs* this worker instance will handle
SCRAPER_WORKER_SHUTDOWN_TIMEOUT="30" # Graceful shutdown timeout in seconds for scraper worker tasks
SCRAPER_ARUN_MANY_TIMEOUT="60.0" # Timeout in seconds for the main crawler.arun_many call
SCREENSHOT_STORAGE_PATH="./storage/screenshots" # Storage path for screenshots

# RAG Configuration
RAG_ENABLED="True"
RAG_EMBEDDING_MODEL="all-MiniLM-L6-v2" # Or another sentence-transformer model
RAG_VECTOR_DB_PATH="./vector_db"
RAG_RELEVANT_CHUNKS_COUNT="5"
RAG_CHUNK_SIZE="500"
RAG_CHUNK_OVERLAP="50"

# Storyboard Settings
STORYBOARD_WPM="150"

# Docker Compose Scaling (for production)
BACKEND_REPLICAS="1"
SCRAPER_REPLICAS="1"
WORKER_BATCH_SIZE="1"
WORKER_CONCURRENT="1"
COMPOSE_BAKE="true"

# Monitoring
GRAFANA_ADMIN_USER=""
GRAFANA_ADMIN_PASSWORD=""
METRICS_ENABLED=""
METRICS_ENDPOINT=""
HEALTH_CHECK_ENABLED=""
HEALTH_CHECK_ENDPOINT=""
TRACING_ENABLED=""
TRACING_EXPORTER=""

BASE_URL="http://localhost:8000"

STORAGE_PROVIDER="local"
LOCAL_STORAGE_PATH="./storage"
AUDIO_STORAGE_PATH="./storage/audio"
STORY_STORAGE_PATH="./storage/stories"
STORYBOARD_STORAGE_PATH="./storage/storyboards"

FILE_RETENTION_DAYS="30"
CLEANUP_INTERVAL_HOURS="24"

S3_BUCKET_NAME=""
S3_REGION="us-east-1"
S3_ACCESS_KEY=""
S3_SECRET_KEY=""
S3_ENDPOINT_URL=""

AZURE_ACCOUNT_NAME=""
AZURE_ACCOUNT_KEY=""
AZURE_CONTAINER_NAME="viralstory"

# Security settings
VOICE_ID_PATTERN=""
SANITIZE_MAX_LENGTH="1000"
DANGEROUS_CHARS=""
ALLOWED_FILE_TYPES="mp3,wav,txt,json"
SOURCE_MATERIALS_PATH="./data/sources"
